{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38d943b-3061-42d1-a699-5ab81a489e6e",
   "metadata": {},
   "source": [
    "# regression decoder test (~10/6/22) (FOR FILIPE DATA ONLY)\n",
    "this compares a fixed decoder, pca decoder, cca transformation (w/ day0 decoder), and a regression decoder on day-N data. the latter two use a day-0 data as a prior start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ff2fbb-e579-471f-b42c-e51c222d33fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.folder_handler import *\n",
    "from src.cort_processor import *\n",
    "from src.cca_processor import *\n",
    "from src.tdt_support import *\n",
    "from src.plotter import *\n",
    "from src.decoders import *\n",
    "from src.utils import *\n",
    "import pickle\n",
    "import scipy as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "from src.wiener_filter import *\n",
    "from matplotlib.pyplot import cm\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f520d7-3e89-4813-b233-90fda2b595d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# set paths/create objects\n",
    "\n",
    "cp1 = day-0\n",
    "\n",
    "cp2 = day-n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb9199-b678-441f-b55a-92e2a31c7447",
   "metadata": {
    "tags": []
   },
   "source": [
    "# pathdump:\n",
    "\n",
    "N5 \n",
    "cp1_path = '/home/diya/Documents/rat-fes/data/filipe_data/N5/N5_170929_No Obstacles_s.mat'\n",
    "cp2_path = '/home/diya/Documents/rat-fes/data/filipe_data/N5/N5_171001_No Obstacles_s.mat'\n",
    "'N5_171016_No Obstacles_s.mat'\n",
    "'N5_171130_No Obstacles_s.mat'\n",
    "\n",
    "n6\n",
    "'N6_171026_No Obstacles_s.mat' this day has pretty low %vaf max\n",
    "'N6_171204_No Obstacles_s.mat'\n",
    "'N6_171211_No Obstacles_s.mat'\n",
    "\n",
    "n9\n",
    "cp1_path = '/home/diya/Documents/rat-fes/data/filipe_data/N9/N9_171121_No Obstacles_s.mat'\n",
    "cp2_path = '/home/diya/Documents/rat-fes/data/filipe_data/N9/N9_171204_No Obstacles_s.mat'\n",
    "'N9_171211_No Obstacles_s.mat'  'N9_171214_No Obstacles_s.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c31a27-24a5-4deb-8614-d6e00505712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is filipe data i belive\n",
      "this is filipe data i belive\n"
     ]
    }
   ],
   "source": [
    "cp1_path = '/home/diya/Documents/rat-fes/data/filipe_data/N5/N5_170929_No Obstacles_s.mat'\n",
    "cp2_path = '/home/diya/Documents/rat-fes/data/filipe_data/N5/N5_171001_No Obstacles_s.mat'\n",
    "\n",
    "cp1 = CortProcessor(cp1_path)\n",
    "cp2 = CortProcessor(cp2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d38c23-b53d-4187-91ad-7efbf9a6e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsampling list, percent of total data\n",
    "subsample_list = np.arange(.005, 1, .005)\n",
    "nummy = cp2.data['rates'][0].shape[0]\n",
    "#newlist = [int(sub * nummy) for sub in subsample_list]\n",
    "\n",
    "#print(f'num_samples:{newlist}')\n",
    "#print(subsample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19955fa1-7e62-47c4-a25e-f425605056eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_num_dimensions=8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ed850-3711-4a76-b317-7c5d551645ba",
   "metadata": {},
   "source": [
    "# getting day0 decoder\n",
    "apply PCA (based on all data), and then train wiener filter.\n",
    "also get a day0-scaled-weights-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f97f4b-6819-4355-bbbc-4305ad07ef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.563\n",
      "0.563\n"
     ]
    }
   ],
   "source": [
    "#get day0 decoder weights, scaled + unscaled versions\n",
    "\n",
    "day0_decoder, nada, naday, nadax = cp1.decode_angles(X=cp1.apply_PCA(dims=lowest_num_dimensions))\n",
    "#lowest_num_dimensions = cp1.num_components\n",
    "print(np.average(nada, 1)[1])\n",
    "\n",
    "X_tempy =cp1.apply_PCA(lowest_num_dimensions)\n",
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(np.squeeze(X_tempy))\n",
    "day0_decoder_scale, nada, naday, nadax = cp1.decode_angles(X=[X_scale])\n",
    "\n",
    "print(np.average(nada, 1)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0409b48-79f7-4e45-9c1f-513fa30e650a",
   "metadata": {},
   "source": [
    "# getting fixed decoder scores\n",
    "1) we subsample Day-N data, and fit PCA transformation. \n",
    "2) we transform entire Day-N data, and decode using Day0 decoder.\n",
    "\n",
    "# getting PCA decoder scores\n",
    "1) we subsample Day-N data, fit PCA transformation, and then transform it. \n",
    "2) We train new PCA decoder on only this low-D subsampled data\n",
    "3) We transform entire Day-N data, and decode using this new PCA decoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b00dfee-7532-4721-b656-2d911659e192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.62, -1.25, -1.61, -1.43, -1.61, -1.67, -1.64, -1.71, -1.78, -1.71, -1.68, -1.68, -1.33, -1.17, -1.6, -0.08, -1.61, -0.02, -1.66, -1.93, -1.97, -1.79, -1.79, -1.62, -1.29, -1.24, -1.21, -1.19, -1.1, -1.03, -1.02, -1.06, -1.04, -1.07, -1.14, -1.13, -1.13, -1.15, -1.15, -1.17, -1.19, -1.18, -1.2, -1.23, -1.24, -1.48, -1.5, -1.52, -1.43, -1.49, -1.47, -1.48, -1.48, -1.49, -1.49, -1.45, -1.45, -1.46, -1.46, -1.47, -1.46, -1.46, -1.85, -1.86, -1.85, -1.85, -1.84, -1.9, -1.84, -1.83, -1.77, -1.77, -1.77, -1.76, -1.77, -1.84, -1.84, -1.83, -1.82, -1.81, -1.81, -1.79, -1.76, -1.74, -1.71, -1.7, -1.68, -1.66, -1.63, -1.62, -1.6, -1.58, -1.56, -1.55, -1.53, -1.52, -1.52, -1.52, -1.53, -1.52, -1.51, -1.4, -1.39, -1.38, -1.37, -1.38, -1.4, -1.52, -1.52, -1.51, -1.52, -1.51, -1.5, -1.49, -1.48, -1.57, -1.57, -1.57, -1.55, -1.55, -1.55, -1.54, -1.52, -1.52, -1.51, -1.5, -1.5, -1.49, -1.48, -1.48, -1.38, -1.47, -1.38, -1.37, -1.36, -1.37, -1.36, -1.46, -1.36, -1.35, -1.35, -1.34, -1.44, -1.43, -1.34, -1.33, -1.31, -1.32, -1.31, -1.32, -1.32, -1.32, -1.32, -1.32, -1.32, -1.32, -1.31, -1.32, -1.32, -1.32, -1.31, -1.31, -1.31, -1.31, -1.33, -1.33, -1.34, -1.34, -1.34, -1.34, -1.34, -1.35, -1.34, -1.34, -1.34, -1.34, -1.35, -1.35, -1.35, -1.35, -1.35, -1.34, -1.34, -1.34, -1.34, -1.34, -1.34, -1.34, -1.34, -1.34, -1.34, -1.33, -1.34, -1.34, -1.33, -1.33, -1.33, -1.32, -1.33]\n",
      "[-834.8, 0.11, 0.45, 0.49, 0.62, 0.65, 0.65, 0.69, 0.71, 0.69, 0.71, 0.72, 0.72, 0.73, 0.73, 0.74, 0.74, 0.74, 0.73, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.73, 0.72, 0.73, 0.72, 0.72, 0.72, 0.71, 0.72, 0.72, 0.73, 0.74, 0.74, 0.74, 0.73, 0.74, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.76, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.77, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.78, 0.79, 0.78, 0.78, 0.78, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79, 0.79]\n"
     ]
    }
   ],
   "source": [
    "fixed_decoder_scores = []\n",
    "pca_decoder_scores = []\n",
    "pca_predic=[]\n",
    "\n",
    "for i in range(len(subsample_list)):\n",
    "    sub_x, sub_y = cp2.subsample(percent = subsample_list[i])\n",
    "    #apply PCA just using subsampled data\n",
    "    sub_x_pca = cp2.apply_PCA(dims=lowest_num_dimensions, X=sub_x)\n",
    "    #save PCA transformation\n",
    "    pca_object = cp2.pca_object\n",
    "    #train PCA decoder \n",
    "    temp_h, nada, nadax, naday = cp2.decode_angles(X=sub_x_pca, Y=sub_y)\n",
    "    \n",
    "    test_x = np.squeeze(np.array(cp2.apply_PCA(dims=lowest_num_dimensions, transformer = pca_object)))\n",
    "    test_y = np.squeeze(np.array(cp2.data['angles']))\n",
    "    \n",
    "    test_x_format, test_y_format = format_data(test_x, test_y)\n",
    "    \n",
    "    temp_y = test_wiener_filter(test_x_format, day0_decoder)\n",
    "    fixed_decoder_scores.append(vaf(test_y_format[:,1], temp_y[:,1]))\n",
    "    \n",
    "    temp_y = test_wiener_filter(test_x_format, temp_h)\n",
    "    pca_decoder_scores.append(vaf(test_y_format[:,1], temp_y[:,1]))\n",
    "    \n",
    "    pca_predic.append(temp_y)\n",
    "\n",
    "print(fixed_decoder_scores)\n",
    "print(pca_decoder_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4288efb-3b3a-4193-aeed-091a173367b3",
   "metadata": {},
   "source": [
    "# cca decoder\n",
    "\n",
    "1) We subsample Day-N data\n",
    "2) We align Day-N subsampled data to Day-0 data\n",
    "3) We fit PCA transformation on subsampled Day-n data, and then transform it\n",
    "4) We fit a CCA transformation on subsampled, low-D day-N data\n",
    "5) We apply our PCA transformation to entire Day-N, and then apply our CCA transformation to entire low-D day-N data\n",
    "6) We decode this using Day-0 decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d5ec33a-9b31-49a4-b5b6-a23660474c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should be good to align\n",
      "(57, 11)\n",
      "(57, 5)\n",
      "(57, 23)\n",
      "(57, 5)\n",
      "should be good to align\n",
      "(84, 11)\n",
      "(84, 5)\n",
      "(84, 23)\n",
      "(84, 5)\n",
      "should be good to align\n",
      "(145, 11)\n",
      "(145, 5)\n",
      "(145, 23)\n",
      "(145, 5)\n",
      "should be good to align\n",
      "(202, 11)\n",
      "(202, 5)\n",
      "(202, 23)\n",
      "(202, 5)\n",
      "should be good to align\n",
      "(246, 11)\n",
      "(246, 5)\n",
      "(246, 23)\n",
      "(246, 5)\n",
      "should be good to align\n",
      "(284, 11)\n",
      "(284, 5)\n",
      "(284, 23)\n",
      "(284, 5)\n",
      "should be good to align\n",
      "(345, 11)\n",
      "(345, 5)\n",
      "(345, 23)\n",
      "(345, 5)\n",
      "should be good to align\n",
      "(443, 11)\n",
      "(443, 5)\n",
      "(443, 23)\n",
      "(443, 5)\n",
      "should be good to align\n",
      "(480, 11)\n",
      "(480, 5)\n",
      "(480, 23)\n",
      "(480, 5)\n",
      "should be good to align\n",
      "(540, 11)\n",
      "(540, 5)\n",
      "(540, 23)\n",
      "(540, 5)\n",
      "should be good to align\n",
      "(603, 11)\n",
      "(603, 5)\n",
      "(603, 23)\n",
      "(603, 5)\n",
      "should be good to align\n",
      "(663, 11)\n",
      "(663, 5)\n",
      "(663, 23)\n",
      "(663, 5)\n",
      "should be good to align\n",
      "(717, 11)\n",
      "(717, 5)\n",
      "(717, 23)\n",
      "(717, 5)\n",
      "should be good to align\n",
      "(782, 11)\n",
      "(782, 5)\n",
      "(782, 23)\n",
      "(782, 5)\n",
      "should be good to align\n",
      "(839, 11)\n",
      "(839, 5)\n",
      "(839, 23)\n",
      "(839, 5)\n",
      "should be good to align\n",
      "(904, 11)\n",
      "(904, 5)\n",
      "(904, 23)\n",
      "(904, 5)\n",
      "should be good to align\n",
      "(939, 11)\n",
      "(939, 5)\n",
      "(939, 23)\n",
      "(939, 5)\n",
      "should be good to align\n",
      "(983, 11)\n",
      "(983, 5)\n",
      "(983, 23)\n",
      "(983, 5)\n",
      "should be good to align\n",
      "(958, 11)\n",
      "(958, 5)\n",
      "(958, 23)\n",
      "(958, 5)\n",
      "should be good to align\n",
      "(1016, 11)\n",
      "(1016, 5)\n",
      "(1016, 23)\n",
      "(1016, 5)\n",
      "should be good to align\n",
      "(1068, 11)\n",
      "(1068, 5)\n",
      "(1068, 23)\n",
      "(1068, 5)\n",
      "should be good to align\n",
      "(1103, 11)\n",
      "(1103, 5)\n",
      "(1103, 23)\n",
      "(1103, 5)\n",
      "should be good to align\n",
      "(1122, 11)\n",
      "(1122, 5)\n",
      "(1122, 23)\n",
      "(1122, 5)\n",
      "should be good to align\n",
      "(1167, 11)\n",
      "(1167, 5)\n",
      "(1167, 23)\n",
      "(1167, 5)\n",
      "should be good to align\n",
      "(1182, 11)\n",
      "(1182, 5)\n",
      "(1182, 23)\n",
      "(1182, 5)\n",
      "should be good to align\n",
      "(1218, 11)\n",
      "(1218, 5)\n",
      "(1218, 23)\n",
      "(1218, 5)\n",
      "should be good to align\n",
      "(1247, 11)\n",
      "(1247, 5)\n",
      "(1247, 23)\n",
      "(1247, 5)\n",
      "should be good to align\n",
      "(1266, 11)\n",
      "(1266, 5)\n",
      "(1266, 23)\n",
      "(1266, 5)\n",
      "should be good to align\n",
      "(1319, 11)\n",
      "(1319, 5)\n",
      "(1319, 23)\n",
      "(1319, 5)\n",
      "should be good to align\n",
      "(1365, 11)\n",
      "(1365, 5)\n",
      "(1365, 23)\n",
      "(1365, 5)\n",
      "should be good to align\n",
      "(1391, 11)\n",
      "(1391, 5)\n",
      "(1391, 23)\n",
      "(1391, 5)\n",
      "should be good to align\n",
      "(1447, 11)\n",
      "(1447, 5)\n",
      "(1447, 23)\n",
      "(1447, 5)\n",
      "should be good to align\n",
      "(1504, 11)\n",
      "(1504, 5)\n",
      "(1504, 23)\n",
      "(1504, 5)\n",
      "should be good to align\n",
      "(1541, 11)\n",
      "(1541, 5)\n",
      "(1541, 23)\n",
      "(1541, 5)\n",
      "should be good to align\n",
      "(1592, 11)\n",
      "(1592, 5)\n",
      "(1592, 23)\n",
      "(1592, 5)\n",
      "should be good to align\n",
      "(1602, 11)\n",
      "(1602, 5)\n",
      "(1602, 23)\n",
      "(1602, 5)\n",
      "should be good to align\n",
      "(1617, 11)\n",
      "(1617, 5)\n",
      "(1617, 23)\n",
      "(1617, 5)\n",
      "should be good to align\n",
      "(1652, 11)\n",
      "(1652, 5)\n",
      "(1652, 23)\n",
      "(1652, 5)\n",
      "should be good to align\n",
      "(1710, 11)\n",
      "(1710, 5)\n",
      "(1710, 23)\n",
      "(1710, 5)\n",
      "should be good to align\n",
      "(1773, 11)\n",
      "(1773, 5)\n",
      "(1773, 23)\n",
      "(1773, 5)\n",
      "should be good to align\n",
      "(1797, 11)\n",
      "(1797, 5)\n",
      "(1797, 23)\n",
      "(1797, 5)\n",
      "should be good to align\n",
      "(1857, 11)\n",
      "(1857, 5)\n",
      "(1857, 23)\n",
      "(1857, 5)\n",
      "should be good to align\n",
      "(1893, 11)\n",
      "(1893, 5)\n",
      "(1893, 23)\n",
      "(1893, 5)\n",
      "should be good to align\n",
      "(1946, 11)\n",
      "(1946, 5)\n",
      "(1946, 23)\n",
      "(1946, 5)\n",
      "should be good to align\n",
      "(1983, 11)\n",
      "(1983, 5)\n",
      "(1983, 23)\n",
      "(1983, 5)\n",
      "should be good to align\n",
      "(2044, 11)\n",
      "(2044, 5)\n",
      "(2044, 23)\n",
      "(2044, 5)\n",
      "should be good to align\n",
      "(2101, 11)\n",
      "(2101, 5)\n",
      "(2101, 23)\n",
      "(2101, 5)\n",
      "should be good to align\n",
      "(2153, 11)\n",
      "(2153, 5)\n",
      "(2153, 23)\n",
      "(2153, 5)\n",
      "should be good to align\n",
      "(2209, 11)\n",
      "(2209, 5)\n",
      "(2209, 23)\n",
      "(2209, 5)\n",
      "should be good to align\n",
      "(2234, 11)\n",
      "(2234, 5)\n",
      "(2234, 23)\n",
      "(2234, 5)\n",
      "should be good to align\n",
      "(2299, 11)\n",
      "(2299, 5)\n",
      "(2299, 23)\n",
      "(2299, 5)\n",
      "should be good to align\n",
      "(2327, 11)\n",
      "(2327, 5)\n",
      "(2327, 23)\n",
      "(2327, 5)\n",
      "should be good to align\n",
      "(2379, 11)\n",
      "(2379, 5)\n",
      "(2379, 23)\n",
      "(2379, 5)\n",
      "should be good to align\n",
      "(2406, 11)\n",
      "(2406, 5)\n",
      "(2406, 23)\n",
      "(2406, 5)\n",
      "should be good to align\n",
      "(2599, 11)\n",
      "(2599, 5)\n",
      "(2599, 23)\n",
      "(2599, 5)\n",
      "should be good to align\n",
      "(2652, 11)\n",
      "(2652, 5)\n",
      "(2652, 23)\n",
      "(2652, 5)\n",
      "should be good to align\n",
      "(2693, 11)\n",
      "(2693, 5)\n",
      "(2693, 23)\n",
      "(2693, 5)\n",
      "should be good to align\n",
      "(2760, 11)\n",
      "(2760, 5)\n",
      "(2760, 23)\n",
      "(2760, 5)\n",
      "should be good to align\n",
      "(2798, 11)\n",
      "(2798, 5)\n",
      "(2798, 23)\n",
      "(2798, 5)\n",
      "should be good to align\n",
      "(2836, 11)\n",
      "(2836, 5)\n",
      "(2836, 23)\n",
      "(2836, 5)\n",
      "should be good to align\n",
      "(2891, 11)\n",
      "(2891, 5)\n",
      "(2891, 23)\n",
      "(2891, 5)\n",
      "should be good to align\n",
      "(2960, 11)\n",
      "(2960, 5)\n",
      "(2960, 23)\n",
      "(2960, 5)\n",
      "should be good to align\n",
      "(2986, 11)\n",
      "(2986, 5)\n",
      "(2986, 23)\n",
      "(2986, 5)\n",
      "should be good to align\n",
      "(3058, 11)\n",
      "(3058, 5)\n",
      "(3058, 23)\n",
      "(3058, 5)\n",
      "should be good to align\n",
      "(3097, 11)\n",
      "(3097, 5)\n",
      "(3097, 23)\n",
      "(3097, 5)\n",
      "should be good to align\n",
      "(3166, 11)\n",
      "(3166, 5)\n",
      "(3166, 23)\n",
      "(3166, 5)\n",
      "should be good to align\n",
      "(3205, 11)\n",
      "(3205, 5)\n",
      "(3205, 23)\n",
      "(3205, 5)\n",
      "should be good to align\n",
      "(3260, 11)\n",
      "(3260, 5)\n",
      "(3260, 23)\n",
      "(3260, 5)\n",
      "should be good to align\n",
      "(3293, 11)\n",
      "(3293, 5)\n",
      "(3293, 23)\n",
      "(3293, 5)\n",
      "should be good to align\n",
      "(3332, 11)\n",
      "(3332, 5)\n",
      "(3332, 23)\n",
      "(3332, 5)\n",
      "should be good to align\n",
      "(3375, 11)\n",
      "(3375, 5)\n",
      "(3375, 23)\n",
      "(3375, 5)\n",
      "should be good to align\n",
      "(3433, 11)\n",
      "(3433, 5)\n",
      "(3433, 23)\n",
      "(3433, 5)\n",
      "should be good to align\n",
      "(3492, 11)\n",
      "(3492, 5)\n",
      "(3492, 23)\n",
      "(3492, 5)\n",
      "should be good to align\n",
      "(3557, 11)\n",
      "(3557, 5)\n",
      "(3557, 23)\n",
      "(3557, 5)\n",
      "should be good to align\n",
      "(3613, 11)\n",
      "(3613, 5)\n",
      "(3613, 23)\n",
      "(3613, 5)\n",
      "should be good to align\n",
      "(3678, 11)\n",
      "(3678, 5)\n",
      "(3678, 23)\n",
      "(3678, 5)\n",
      "should be good to align\n",
      "(3733, 11)\n",
      "(3733, 5)\n",
      "(3733, 23)\n",
      "(3733, 5)\n",
      "should be good to align\n",
      "(3798, 11)\n",
      "(3798, 5)\n",
      "(3798, 23)\n",
      "(3798, 5)\n",
      "should be good to align\n",
      "(3841, 11)\n",
      "(3841, 5)\n",
      "(3841, 23)\n",
      "(3841, 5)\n",
      "should be good to align\n",
      "(3878, 11)\n",
      "(3878, 5)\n",
      "(3878, 23)\n",
      "(3878, 5)\n",
      "should be good to align\n",
      "(3923, 11)\n",
      "(3923, 5)\n",
      "(3923, 23)\n",
      "(3923, 5)\n",
      "should be good to align\n",
      "(3980, 11)\n",
      "(3980, 5)\n",
      "(3980, 23)\n",
      "(3980, 5)\n",
      "should be good to align\n",
      "(4038, 11)\n",
      "(4038, 5)\n",
      "(4038, 23)\n",
      "(4038, 5)\n",
      "should be good to align\n",
      "(4087, 11)\n",
      "(4087, 5)\n",
      "(4087, 23)\n",
      "(4087, 5)\n",
      "should be good to align\n",
      "(4148, 11)\n",
      "(4148, 5)\n",
      "(4148, 23)\n",
      "(4148, 5)\n",
      "should be good to align\n",
      "(4163, 11)\n",
      "(4163, 5)\n",
      "(4163, 23)\n",
      "(4163, 5)\n",
      "should be good to align\n",
      "(4217, 11)\n",
      "(4217, 5)\n",
      "(4217, 23)\n",
      "(4217, 5)\n",
      "should be good to align\n",
      "(4259, 11)\n",
      "(4259, 5)\n",
      "(4259, 23)\n",
      "(4259, 5)\n",
      "should be good to align\n",
      "(4316, 11)\n",
      "(4316, 5)\n",
      "(4316, 23)\n",
      "(4316, 5)\n",
      "should be good to align\n",
      "(4361, 11)\n",
      "(4361, 5)\n",
      "(4361, 23)\n",
      "(4361, 5)\n",
      "should be good to align\n",
      "(4428, 11)\n",
      "(4428, 5)\n",
      "(4428, 23)\n",
      "(4428, 5)\n",
      "should be good to align\n",
      "(4488, 11)\n",
      "(4488, 5)\n",
      "(4488, 23)\n",
      "(4488, 5)\n",
      "should be good to align\n",
      "(4544, 11)\n",
      "(4544, 5)\n",
      "(4544, 23)\n",
      "(4544, 5)\n",
      "should be good to align\n",
      "(4600, 11)\n",
      "(4600, 5)\n",
      "(4600, 23)\n",
      "(4600, 5)\n",
      "should be good to align\n",
      "(4665, 11)\n",
      "(4665, 5)\n",
      "(4665, 23)\n",
      "(4665, 5)\n",
      "should be good to align\n",
      "(4721, 11)\n",
      "(4721, 5)\n",
      "(4721, 23)\n",
      "(4721, 5)\n",
      "should be good to align\n",
      "(4789, 11)\n",
      "(4789, 5)\n",
      "(4789, 23)\n",
      "(4789, 5)\n",
      "should be good to align\n",
      "(4845, 11)\n",
      "(4845, 5)\n",
      "(4845, 23)\n",
      "(4845, 5)\n",
      "should be good to align\n",
      "(4902, 11)\n",
      "(4902, 5)\n",
      "(4902, 23)\n",
      "(4902, 5)\n",
      "should be good to align\n",
      "(4970, 11)\n",
      "(4970, 5)\n",
      "(4970, 23)\n",
      "(4970, 5)\n",
      "should be good to align\n",
      "(5012, 11)\n",
      "(5012, 5)\n",
      "(5012, 23)\n",
      "(5012, 5)\n",
      "should be good to align\n",
      "(5037, 11)\n",
      "(5037, 5)\n",
      "(5037, 23)\n",
      "(5037, 5)\n",
      "should be good to align\n",
      "(5094, 11)\n",
      "(5094, 5)\n",
      "(5094, 23)\n",
      "(5094, 5)\n",
      "should be good to align\n",
      "(5146, 11)\n",
      "(5146, 5)\n",
      "(5146, 23)\n",
      "(5146, 5)\n",
      "should be good to align\n",
      "(5206, 11)\n",
      "(5206, 5)\n",
      "(5206, 23)\n",
      "(5206, 5)\n",
      "should be good to align\n",
      "(5262, 11)\n",
      "(5262, 5)\n",
      "(5262, 23)\n",
      "(5262, 5)\n",
      "should be good to align\n",
      "(5320, 11)\n",
      "(5320, 5)\n",
      "(5320, 23)\n",
      "(5320, 5)\n",
      "should be good to align\n",
      "(5363, 11)\n",
      "(5363, 5)\n",
      "(5363, 23)\n",
      "(5363, 5)\n",
      "should be good to align\n",
      "(5420, 11)\n",
      "(5420, 5)\n",
      "(5420, 23)\n",
      "(5420, 5)\n",
      "should be good to align\n",
      "(5461, 11)\n",
      "(5461, 5)\n",
      "(5461, 23)\n",
      "(5461, 5)\n",
      "should be good to align\n",
      "(5520, 11)\n",
      "(5520, 5)\n",
      "(5520, 23)\n",
      "(5520, 5)\n",
      "should be good to align\n",
      "(5571, 11)\n",
      "(5571, 5)\n",
      "(5571, 23)\n",
      "(5571, 5)\n",
      "should be good to align\n",
      "(5631, 11)\n",
      "(5631, 5)\n",
      "(5631, 23)\n",
      "(5631, 5)\n",
      "should be good to align\n",
      "(5673, 11)\n",
      "(5673, 5)\n",
      "(5673, 23)\n",
      "(5673, 5)\n",
      "should be good to align\n",
      "(5713, 11)\n",
      "(5713, 5)\n",
      "(5713, 23)\n",
      "(5713, 5)\n",
      "should be good to align\n",
      "(5754, 11)\n",
      "(5754, 5)\n",
      "(5754, 23)\n",
      "(5754, 5)\n",
      "should be good to align\n",
      "(5794, 11)\n",
      "(5794, 5)\n",
      "(5794, 23)\n",
      "(5794, 5)\n",
      "should be good to align\n",
      "(5853, 11)\n",
      "(5853, 5)\n",
      "(5853, 23)\n",
      "(5853, 5)\n",
      "should be good to align\n",
      "(5910, 11)\n",
      "(5910, 5)\n",
      "(5910, 23)\n",
      "(5910, 5)\n",
      "should be good to align\n",
      "(5966, 11)\n",
      "(5966, 5)\n",
      "(5966, 23)\n",
      "(5966, 5)\n",
      "should be good to align\n",
      "(6017, 11)\n",
      "(6017, 5)\n",
      "(6017, 23)\n",
      "(6017, 5)\n",
      "should be good to align\n",
      "(6042, 11)\n",
      "(6042, 5)\n",
      "(6042, 23)\n",
      "(6042, 5)\n",
      "should be good to align\n",
      "(6093, 11)\n",
      "(6093, 5)\n",
      "(6093, 23)\n",
      "(6093, 5)\n",
      "should be good to align\n",
      "(6160, 11)\n",
      "(6160, 5)\n",
      "(6160, 23)\n",
      "(6160, 5)\n",
      "should be good to align\n",
      "(6215, 11)\n",
      "(6215, 5)\n",
      "(6215, 23)\n",
      "(6215, 5)\n",
      "should be good to align\n",
      "(6274, 11)\n",
      "(6274, 5)\n",
      "(6274, 23)\n",
      "(6274, 5)\n",
      "should be good to align\n",
      "(6288, 11)\n",
      "(6288, 5)\n",
      "(6288, 23)\n",
      "(6288, 5)\n",
      "should be good to align\n",
      "(6342, 11)\n",
      "(6342, 5)\n",
      "(6342, 23)\n",
      "(6342, 5)\n",
      "should be good to align\n",
      "(6382, 11)\n",
      "(6382, 5)\n",
      "(6382, 23)\n",
      "(6382, 5)\n",
      "should be good to align\n",
      "(6438, 11)\n",
      "(6438, 5)\n",
      "(6438, 23)\n",
      "(6438, 5)\n",
      "should be good to align\n",
      "(6496, 11)\n",
      "(6496, 5)\n",
      "(6496, 23)\n",
      "(6496, 5)\n",
      "should be good to align\n",
      "(6547, 11)\n",
      "(6547, 5)\n",
      "(6547, 23)\n",
      "(6547, 5)\n",
      "should be good to align\n",
      "(6601, 11)\n",
      "(6601, 5)\n",
      "(6601, 23)\n",
      "(6601, 5)\n",
      "should be good to align\n",
      "(6667, 11)\n",
      "(6667, 5)\n",
      "(6667, 23)\n",
      "(6667, 5)\n",
      "should be good to align\n",
      "(6709, 11)\n",
      "(6709, 5)\n",
      "(6709, 23)\n",
      "(6709, 5)\n",
      "should be good to align\n",
      "(6733, 11)\n",
      "(6733, 5)\n",
      "(6733, 23)\n",
      "(6733, 5)\n",
      "should be good to align\n",
      "(6786, 11)\n",
      "(6786, 5)\n",
      "(6786, 23)\n",
      "(6786, 5)\n",
      "should be good to align\n",
      "(6844, 11)\n",
      "(6844, 5)\n",
      "(6844, 23)\n",
      "(6844, 5)\n",
      "should be good to align\n",
      "(6914, 11)\n",
      "(6914, 5)\n",
      "(6914, 23)\n",
      "(6914, 5)\n",
      "should be good to align\n",
      "(6970, 11)\n",
      "(6970, 5)\n",
      "(6970, 23)\n",
      "(6970, 5)\n",
      "should be good to align\n",
      "(7028, 11)\n",
      "(7028, 5)\n",
      "(7028, 23)\n",
      "(7028, 5)\n",
      "should be good to align\n",
      "(7067, 11)\n",
      "(7067, 5)\n",
      "(7067, 23)\n",
      "(7067, 5)\n",
      "should be good to align\n",
      "(7119, 11)\n",
      "(7119, 5)\n",
      "(7119, 23)\n",
      "(7119, 5)\n",
      "should be good to align\n",
      "(7175, 11)\n",
      "(7175, 5)\n",
      "(7175, 23)\n",
      "(7175, 5)\n",
      "should be good to align\n",
      "(7233, 11)\n",
      "(7233, 5)\n",
      "(7233, 23)\n",
      "(7233, 5)\n",
      "should be good to align\n",
      "(7244, 11)\n",
      "(7244, 5)\n",
      "(7244, 23)\n",
      "(7244, 5)\n",
      "should be good to align\n",
      "(7282, 11)\n",
      "(7282, 5)\n",
      "(7282, 23)\n",
      "(7282, 5)\n",
      "should be good to align\n",
      "(7336, 11)\n",
      "(7336, 5)\n",
      "(7336, 23)\n",
      "(7336, 5)\n",
      "should be good to align\n",
      "(7406, 11)\n",
      "(7406, 5)\n",
      "(7406, 23)\n",
      "(7406, 5)\n",
      "should be good to align\n",
      "(7463, 11)\n",
      "(7463, 5)\n",
      "(7463, 23)\n",
      "(7463, 5)\n",
      "should be good to align\n",
      "(7521, 11)\n",
      "(7521, 5)\n",
      "(7521, 23)\n",
      "(7521, 5)\n",
      "should be good to align\n",
      "(7577, 11)\n",
      "(7577, 5)\n",
      "(7577, 23)\n",
      "(7577, 5)\n",
      "should be good to align\n",
      "(7644, 11)\n",
      "(7644, 5)\n",
      "(7644, 23)\n",
      "(7644, 5)\n",
      "should be good to align\n",
      "(7704, 11)\n",
      "(7704, 5)\n",
      "(7704, 23)\n",
      "(7704, 5)\n",
      "should be good to align\n",
      "(7761, 11)\n",
      "(7761, 5)\n",
      "(7761, 23)\n",
      "(7761, 5)\n",
      "should be good to align\n",
      "(7800, 11)\n",
      "(7800, 5)\n",
      "(7800, 23)\n",
      "(7800, 5)\n",
      "should be good to align\n",
      "(7900, 11)\n",
      "(7900, 5)\n",
      "(7900, 23)\n",
      "(7900, 5)\n",
      "should be good to align\n",
      "(7942, 11)\n",
      "(7942, 5)\n",
      "(7942, 23)\n",
      "(7942, 5)\n",
      "should be good to align\n",
      "(7941, 11)\n",
      "(7941, 5)\n",
      "(7941, 23)\n",
      "(7941, 5)\n",
      "should be good to align\n",
      "(8074, 11)\n",
      "(8074, 5)\n",
      "(8074, 23)\n",
      "(8074, 5)\n",
      "should be good to align\n",
      "(8134, 11)\n",
      "(8134, 5)\n",
      "(8134, 23)\n",
      "(8134, 5)\n",
      "should be good to align\n",
      "(8201, 11)\n",
      "(8201, 5)\n",
      "(8201, 23)\n",
      "(8201, 5)\n",
      "should be good to align\n",
      "(8252, 11)\n",
      "(8252, 5)\n",
      "(8252, 23)\n",
      "(8252, 5)\n",
      "should be good to align\n",
      "(8299, 11)\n",
      "(8299, 5)\n",
      "(8299, 23)\n",
      "(8299, 5)\n",
      "should be good to align\n",
      "(8338, 11)\n",
      "(8338, 5)\n",
      "(8338, 23)\n",
      "(8338, 5)\n",
      "should be good to align\n",
      "(8397, 11)\n",
      "(8397, 5)\n",
      "(8397, 23)\n",
      "(8397, 5)\n",
      "should be good to align\n",
      "(8425, 11)\n",
      "(8425, 5)\n",
      "(8425, 23)\n",
      "(8425, 5)\n",
      "should be good to align\n",
      "(8452, 11)\n",
      "(8452, 5)\n",
      "(8452, 23)\n",
      "(8452, 5)\n",
      "should be good to align\n",
      "(8493, 11)\n",
      "(8493, 5)\n",
      "(8493, 23)\n",
      "(8493, 5)\n",
      "should be good to align\n",
      "(8553, 11)\n",
      "(8553, 5)\n",
      "(8553, 23)\n",
      "(8553, 5)\n",
      "should be good to align\n",
      "(8595, 11)\n",
      "(8595, 5)\n",
      "(8595, 23)\n",
      "(8595, 5)\n",
      "should be good to align\n",
      "(8627, 11)\n",
      "(8627, 5)\n",
      "(8627, 23)\n",
      "(8627, 5)\n",
      "should be good to align\n",
      "(8674, 11)\n",
      "(8674, 5)\n",
      "(8674, 23)\n",
      "(8674, 5)\n",
      "should be good to align\n",
      "(8718, 11)\n",
      "(8718, 5)\n",
      "(8718, 23)\n",
      "(8718, 5)\n",
      "should be good to align\n",
      "(8746, 11)\n",
      "(8746, 5)\n",
      "(8746, 23)\n",
      "(8746, 5)\n",
      "should be good to align\n",
      "(8764, 11)\n",
      "(8764, 5)\n",
      "(8764, 23)\n",
      "(8764, 5)\n",
      "should be good to align\n",
      "(8792, 11)\n",
      "(8792, 5)\n",
      "(8792, 23)\n",
      "(8792, 5)\n",
      "should be good to align\n",
      "(8805, 11)\n",
      "(8805, 5)\n",
      "(8805, 23)\n",
      "(8805, 5)\n",
      "should be good to align\n",
      "(8809, 11)\n",
      "(8809, 5)\n",
      "(8809, 23)\n",
      "(8809, 5)\n",
      "should be good to align\n",
      "(8826, 11)\n",
      "(8826, 5)\n",
      "(8826, 23)\n",
      "(8826, 5)\n",
      "should be good to align\n",
      "(8839, 11)\n",
      "(8839, 5)\n",
      "(8839, 23)\n",
      "(8839, 5)\n",
      "should be good to align\n",
      "(8856, 11)\n",
      "(8856, 5)\n",
      "(8856, 23)\n",
      "(8856, 5)\n",
      "should be good to align\n",
      "(8873, 11)\n",
      "(8873, 5)\n",
      "(8873, 23)\n",
      "(8873, 5)\n",
      "should be good to align\n",
      "(8890, 11)\n",
      "(8890, 5)\n",
      "(8890, 23)\n",
      "(8890, 5)\n",
      "should be good to align\n",
      "(8873, 11)\n",
      "(8873, 5)\n",
      "(8873, 23)\n",
      "(8873, 5)\n",
      "should be good to align\n",
      "(8890, 11)\n",
      "(8890, 5)\n",
      "(8890, 23)\n",
      "(8890, 5)\n",
      "should be good to align\n",
      "(8890, 11)\n",
      "(8890, 5)\n",
      "(8890, 23)\n",
      "(8890, 5)\n",
      "should be good to align\n",
      "(8907, 11)\n",
      "(8907, 5)\n",
      "(8907, 23)\n",
      "(8907, 5)\n",
      "should be good to align\n",
      "(8918, 11)\n",
      "(8918, 5)\n",
      "(8918, 23)\n",
      "(8918, 5)\n",
      "should be good to align\n",
      "(8918, 11)\n",
      "(8918, 5)\n",
      "(8918, 23)\n",
      "(8918, 5)\n",
      "should be good to align\n",
      "(8918, 11)\n",
      "(8918, 5)\n",
      "(8918, 23)\n",
      "(8918, 5)\n",
      "should be good to align\n",
      "(8918, 11)\n",
      "(8918, 5)\n",
      "(8918, 23)\n",
      "(8918, 5)\n",
      "should be good to align\n",
      "(8918, 11)\n",
      "(8918, 5)\n",
      "(8918, 23)\n",
      "(8918, 5)\n",
      "should be good to align\n",
      "(8918, 11)\n",
      "(8918, 5)\n",
      "(8918, 23)\n",
      "(8918, 5)\n",
      "should be good to align\n",
      "(8918, 11)\n",
      "(8918, 5)\n",
      "(8918, 23)\n",
      "(8918, 5)\n",
      "should be good to align\n",
      "(8918, 11)\n",
      "(8918, 5)\n",
      "(8918, 23)\n",
      "(8918, 5)\n",
      "should be good to align\n",
      "(8935, 11)\n",
      "(8935, 5)\n",
      "(8935, 23)\n",
      "(8935, 5)\n",
      "should be good to align\n",
      "(8935, 11)\n",
      "(8935, 5)\n",
      "(8935, 23)\n",
      "(8935, 5)\n",
      "should be good to align\n",
      "(8946, 11)\n",
      "(8946, 5)\n",
      "(8946, 23)\n",
      "(8946, 5)\n"
     ]
    }
   ],
   "source": [
    "cca_decoder_scores = []\n",
    "cca_transformers=[]\n",
    "for i in range(len(subsample_list)):\n",
    "    #make subsampled cp2\n",
    "    temp_cp2 = copy.deepcopy(cp2)\n",
    "    sub_x2, sub_y2 = temp_cp2.subsample(percent = subsample_list[i])\n",
    "    \n",
    "    temp_cp2.data['rates'] = sub_x2\n",
    "    temp_cp2.data['angles'] = sub_y2\n",
    "    \n",
    "    temp_cca = CCAProcessor(cp1, temp_cp2)\n",
    "    \n",
    "    pca_sub_x1, pca_sub_x2 = temp_cca.apply_PCA(preset_num_components=lowest_num_dimensions)\n",
    "    temp_cca_transformer, nada = temp_cca.apply_CCA(preset_num_components = lowest_num_dimensions)\n",
    "    \n",
    "    cca_transformers.append(temp_cca_transformer)\n",
    "    \n",
    "    test_x = np.squeeze(np.array(cp2.apply_PCA(dims=lowest_num_dimensions, transformer = temp_cca.data['cp2']['pca_transformer'])))\n",
    "    test_y = np.squeeze(np.array(cp2.data['angles']))\n",
    "    \n",
    "    nada, test_x_cca_space = temp_cca_transformer.transform(test_x, test_x)\n",
    "    \n",
    "    temp_x = temp_cca_transformer.inverse_transform(test_x_cca_space)\n",
    "    \n",
    "    temp_x_format, test_y_format = format_data(temp_x, test_y)\n",
    "    predic = test_wiener_filter(temp_x_format, day0_decoder)\n",
    "    \n",
    "    cca_decoder_scores.append(vaf(test_y_format[:,1], predic[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb28724-8f37-4ca3-8c07-77bf80fe72e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.26,\n",
       " -0.47,\n",
       " 0.37,\n",
       " 0.44,\n",
       " 0.26,\n",
       " 0.02,\n",
       " 0.59,\n",
       " 0.61,\n",
       " 0.64,\n",
       " -0.21,\n",
       " 0.45,\n",
       " 0.49,\n",
       " 0.59,\n",
       " 0.5,\n",
       " -0.79,\n",
       " -0.79,\n",
       " -0.72,\n",
       " 0.54,\n",
       " -0.36,\n",
       " -0.35,\n",
       " 0.56,\n",
       " 0.55,\n",
       " -0.41,\n",
       " -0.48,\n",
       " -0.42,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.62,\n",
       " 0.6,\n",
       " 0.58,\n",
       " 0.58,\n",
       " 0.58,\n",
       " 0.57,\n",
       " 0.56,\n",
       " 0.55,\n",
       " 0.55,\n",
       " -0.18,\n",
       " -0.13,\n",
       " -0.07,\n",
       " -0.1,\n",
       " 0.52,\n",
       " 0.48,\n",
       " 0.48,\n",
       " 0.51,\n",
       " 0.53,\n",
       " 0.58,\n",
       " 0.5,\n",
       " 0.51,\n",
       " 0.51,\n",
       " 0.52,\n",
       " 0.53,\n",
       " 0.54,\n",
       " 0.55,\n",
       " 0.54,\n",
       " 0.52,\n",
       " 0.53,\n",
       " 0.56,\n",
       " 0.56,\n",
       " 0.56,\n",
       " 0.55,\n",
       " 0.56,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.56,\n",
       " 0.57,\n",
       " 0.58,\n",
       " 0.57,\n",
       " 0.59,\n",
       " 0.59,\n",
       " 0.59,\n",
       " 0.59,\n",
       " 0.59,\n",
       " 0.59,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.56,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.58,\n",
       " 0.61,\n",
       " 0.62,\n",
       " 0.65,\n",
       " 0.64,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.58,\n",
       " 0.58,\n",
       " 0.56,\n",
       " 0.56,\n",
       " 0.56,\n",
       " 0.53,\n",
       " 0.64,\n",
       " 0.53,\n",
       " 0.54,\n",
       " 0.63,\n",
       " 0.53,\n",
       " 0.54,\n",
       " 0.54,\n",
       " 0.55,\n",
       " 0.55,\n",
       " 0.55,\n",
       " 0.55,\n",
       " 0.55,\n",
       " 0.55,\n",
       " 0.56,\n",
       " 0.55,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.54,\n",
       " 0.53,\n",
       " 0.54,\n",
       " 0.63,\n",
       " 0.54,\n",
       " 0.65,\n",
       " 0.65,\n",
       " 0.64,\n",
       " 0.65,\n",
       " 0.65,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.65,\n",
       " 0.63,\n",
       " 0.65,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.66,\n",
       " 0.67,\n",
       " 0.59,\n",
       " 0.62,\n",
       " 0.62,\n",
       " 0.64,\n",
       " 0.63,\n",
       " 0.66,\n",
       " 0.65,\n",
       " 0.63,\n",
       " 0.58,\n",
       " 0.58,\n",
       " 0.58,\n",
       " 0.58,\n",
       " 0.58,\n",
       " 0.59,\n",
       " 0.58,\n",
       " 0.58,\n",
       " 0.58,\n",
       " 0.58,\n",
       " 0.58,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57,\n",
       " 0.57]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cca_decoder_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af66572-df24-4048-b460-00fbb083c696",
   "metadata": {},
   "source": [
    "# regression fit\n",
    "1) We subsample day-n data, fit PCA transformation, and then transform it\n",
    "2) We then transform it using CCA transformation corresponding to same subsample we got in the CCA part. \n",
    "3) We scale it. #TODO try using day0 scale to transform it\n",
    "4) We feed this subsampled, low-d, CCA-transformed day-n data into our regression decoder. It spits out a new decoder.\n",
    "5) We take entire Day-N data, transform it with both PCA/CCA corresponding to subsample, scale it, and then decode using our new decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8a8afdf-80c9-44d4-bbba-93b4664083c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_scoring is : -0.03\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : -0.74\n",
      "new_scoring is: 0.8\n",
      "initial_scoring is : 0.04\n",
      "new_scoring is: 0.8\n",
      "initial_scoring is : 0.37\n",
      "new_scoring is: 0.8\n",
      "initial_scoring is : 0.04\n",
      "new_scoring is: 0.8\n",
      "initial_scoring is : 0.02\n",
      "new_scoring is: 0.82\n",
      "initial_scoring is : 0.47\n",
      "new_scoring is: 0.83\n",
      "initial_scoring is : 0.69\n",
      "new_scoring is: 0.83\n",
      "initial_scoring is : 0.7\n",
      "new_scoring is: 0.83\n",
      "initial_scoring is : -0.14\n",
      "new_scoring is: 0.81\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.82\n",
      "initial_scoring is : 0.62\n",
      "new_scoring is: 0.81\n",
      "initial_scoring is : 0.66\n",
      "new_scoring is: 0.81\n",
      "initial_scoring is : 0.38\n",
      "new_scoring is: 0.81\n",
      "initial_scoring is : -0.9\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : -0.22\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : -0.46\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.47\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : -0.59\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : -0.54\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.48\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.49\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : -0.26\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : -0.1\n",
      "new_scoring is: 0.74\n",
      "initial_scoring is : -0.82\n",
      "new_scoring is: 0.73\n",
      "initial_scoring is : 0.35\n",
      "new_scoring is: 0.73\n",
      "initial_scoring is : 0.32\n",
      "new_scoring is: 0.73\n",
      "initial_scoring is : 0.33\n",
      "new_scoring is: 0.72\n",
      "initial_scoring is : 0.45\n",
      "new_scoring is: 0.72\n",
      "initial_scoring is : 0.42\n",
      "new_scoring is: 0.72\n",
      "initial_scoring is : 0.41\n",
      "new_scoring is: 0.71\n",
      "initial_scoring is : 0.37\n",
      "new_scoring is: 0.71\n",
      "initial_scoring is : 0.4\n",
      "new_scoring is: 0.71\n",
      "initial_scoring is : 0.36\n",
      "new_scoring is: 0.71\n",
      "initial_scoring is : 0.37\n",
      "new_scoring is: 0.71\n",
      "initial_scoring is : 0.36\n",
      "new_scoring is: 0.71\n",
      "initial_scoring is : -0.17\n",
      "new_scoring is: 0.71\n",
      "initial_scoring is : -0.15\n",
      "new_scoring is: 0.7\n",
      "initial_scoring is : -0.17\n",
      "new_scoring is: 0.7\n",
      "initial_scoring is : -0.16\n",
      "new_scoring is: 0.7\n",
      "initial_scoring is : 0.35\n",
      "new_scoring is: 0.71\n",
      "initial_scoring is : 0.28\n",
      "new_scoring is: 0.71\n",
      "initial_scoring is : 0.22\n",
      "new_scoring is: 0.71\n",
      "initial_scoring is : 0.28\n",
      "new_scoring is: 0.71\n",
      "initial_scoring is : 0.29\n",
      "new_scoring is: 0.71\n",
      "initial_scoring is : 0.36\n",
      "new_scoring is: 0.72\n",
      "initial_scoring is : 0.3\n",
      "new_scoring is: 0.72\n",
      "initial_scoring is : 0.3\n",
      "new_scoring is: 0.72\n",
      "initial_scoring is : 0.36\n",
      "new_scoring is: 0.72\n",
      "initial_scoring is : 0.38\n",
      "new_scoring is: 0.72\n",
      "initial_scoring is : 0.39\n",
      "new_scoring is: 0.72\n",
      "initial_scoring is : 0.42\n",
      "new_scoring is: 0.72\n",
      "initial_scoring is : 0.42\n",
      "new_scoring is: 0.73\n",
      "initial_scoring is : 0.42\n",
      "new_scoring is: 0.73\n",
      "initial_scoring is : 0.43\n",
      "new_scoring is: 0.73\n",
      "initial_scoring is : 0.44\n",
      "new_scoring is: 0.73\n",
      "initial_scoring is : 0.48\n",
      "new_scoring is: 0.74\n",
      "initial_scoring is : 0.48\n",
      "new_scoring is: 0.74\n",
      "initial_scoring is : 0.48\n",
      "new_scoring is: 0.74\n",
      "initial_scoring is : 0.41\n",
      "new_scoring is: 0.74\n",
      "initial_scoring is : 0.41\n",
      "new_scoring is: 0.74\n",
      "initial_scoring is : 0.4\n",
      "new_scoring is: 0.74\n",
      "initial_scoring is : 0.48\n",
      "new_scoring is: 0.74\n",
      "initial_scoring is : 0.51\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.5\n",
      "new_scoring is: 0.74\n",
      "initial_scoring is : 0.5\n",
      "new_scoring is: 0.74\n",
      "initial_scoring is : 0.5\n",
      "new_scoring is: 0.74\n",
      "initial_scoring is : 0.49\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.52\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.49\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.52\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.52\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.53\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.54\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.55\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.55\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.55\n",
      "new_scoring is: 0.75\n",
      "initial_scoring is : 0.55\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.55\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.58\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.58\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.59\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.63\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.63\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.58\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.58\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.59\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.59\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.55\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.76\n",
      "initial_scoring is : 0.55\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.63\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.55\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.55\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.63\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.55\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.56\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.6\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.62\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.65\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.57\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.65\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.65\n",
      "new_scoring is: 0.77\n",
      "initial_scoring is : 0.65\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.66\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.66\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.68\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.67\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.68\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.68\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.68\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.68\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.67\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.68\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.66\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.64\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.67\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.67\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.67\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.68\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.67\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.69\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.69\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.68\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.69\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.62\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.65\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.65\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.65\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.64\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.68\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.68\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.66\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.78\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.6\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.6\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.6\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.6\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.62\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.62\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.62\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n",
      "initial_scoring is : 0.61\n",
      "new_scoring is: 0.79\n"
     ]
    }
   ],
   "source": [
    "r_scores = []\n",
    "r_predic=[]\n",
    "\n",
    "for i in range(len(subsample_list)):\n",
    "    #subsample day-n unprocessed data\n",
    "    sub_x, sub_y = cp2.subsample(percent = subsample_list[i])\n",
    "    \n",
    "    #apply PCA to subsampled data\n",
    "    sub_x_pca = np.squeeze(cp2.apply_PCA(dims=lowest_num_dimensions, X=sub_x))\n",
    "    #transform PCA subsample to day-0 shape\n",
    "    nada, sub_x_cca_space = cca_transformers[i].transform(sub_x_pca, sub_x_pca)\n",
    "    temp_x = cca_transformers[i].inverse_transform(sub_x_cca_space)\n",
    "    #scale transformed data \n",
    "    scaler = StandardScaler()\n",
    "    temp_x_scale = scaler.fit_transform(temp_x)\n",
    "    \n",
    "    temp_x_format, temp_y_format = format_data(temp_x_scale, sub_y[0])\n",
    "    wpost, nada = ridge_fit(b0=day0_decoder_scale, x_format = temp_x_format, y_format = temp_y_format, my_alpha=100.0)\n",
    "    \n",
    "    \n",
    "    ###now lets test on full dataset\n",
    "    test_x = np.squeeze(np.array(cp2.apply_PCA(dims=lowest_num_dimensions, transformer = cp2.pca_object)))\n",
    "    test_y = np.squeeze(np.array(cp2.data['angles']))\n",
    "    \n",
    "    nada, test_xx = temp_cca.apply_CCA(cp2_x = test_x, transformer = cca_transformers[i])\n",
    "    test_xx_scale = scaler.transform(test_xx)\n",
    "    test_xx_scale_format, nada = format_data(test_xx_scale, test_y)\n",
    "    temp_y = test_wiener_filter(test_xx_scale_format, wpost)\n",
    "    \n",
    "    r_predic.append(temp_y)  \n",
    "    predic = vaf(test_y_format[:,1], temp_y[:,1])\n",
    "    \n",
    " \n",
    "    r_scores.append(predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2f36073-6a75-49f7-bec8-98828e83a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# %matplotlib widget\n",
    "\n",
    "# plot_dict = {}\n",
    "# plot_dict['fixed_decoder_scores'] = fixed_decoder_scores\n",
    "# plot_dict['pca_decoder_scores'] = pca_decoder_scores\n",
    "# plot_dict['cca_decoder_scores'] = cca_decoder_scores\n",
    "# plot_dict['r_decoder_scores'] = r_scores\n",
    "\n",
    "# index = subsample_list\n",
    "\n",
    "# df = pd.DataFrame(data=plot_dict, index=index)\n",
    "\n",
    "  \n",
    "# # plot grouped bar chart\n",
    "# ax = df.plot.bar(rot=15)\n",
    "# ax.set_ylim(bottom=-1, top=1)\n",
    "# ax.set_title('Training various decoders, trying on Day-N data')\n",
    "# ax.set_ylabel('r^2')\n",
    "# ax.set_xlabel('percent of total day-n data')\n",
    "# ax.legend(loc='lower right')\n",
    "# for container in ax.containers:\n",
    "#     ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e57165-3d3a-4c11-9ae2-5a61e65ea668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig0 = plt.figure()\n",
    "# ax0 = fig0.add_subplot(211)\n",
    "# ts = np.arange(0, test_y_format.shape[0]/50, 1/50)\n",
    "\n",
    "# num =0 \n",
    "\n",
    "# legend1=['actual', 'pca_predic']\n",
    "# legend2=['actual','r_predic']\n",
    "\n",
    "\n",
    "# ax0.plot(ts, test_y_format[:,1])\n",
    "# ax0.plot(ts, pca_predic[num][:,1])\n",
    "# ax0.legend(legend1, loc='lower right')\n",
    "\n",
    "# ax01 = fig0.add_subplot(212, sharex=ax0)\n",
    "# ax01.plot(ts, test_y_format[:,1])\n",
    "# ax01.plot(ts, r_predic[num][:,1])\n",
    "# ax01.legend(legend2, loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6adc6f60-38d8-4acd-bc42-f992471d9709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe19fc8a9e8>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5422fcf47c014a23af91030d0d08c493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1= fig1.add_subplot(111)\n",
    "x = subsample_list\n",
    "ax1.set_ylim(bottom=-1, top=1)\n",
    "ax1.scatter(x, pca_decoder_scores)\n",
    "ax1.plot(x, pca_decoder_scores)\n",
    "ax1.scatter(x, r_scores)\n",
    "ax1.plot(x, r_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f62db9-dc86-49f0-a902-54a4779c1f0f",
   "metadata": {},
   "source": [
    "# notes\n",
    "\n",
    "cp1_path = '/home/diya/Documents/rat-fes/data/filipe_data/N5/N5_171016_No Obstacles_s.mat'\n",
    "cp2_path = '/home/diya/Documents/rat-fes/data/filipe_data/N6/N6_171204_No Obstacles_s.mat'\n",
    "\n",
    "with these two, regression is good vaf score but in practicality something seems off!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e1ae2-4e5e-4360-a6f8-bbc9ac656fa2",
   "metadata": {},
   "source": [
    "# paths\n",
    "\n",
    "N5 \n",
    "cp1_path = '/home/diya/Documents/rat-fes/data/filipe_data/N5/N5_170929_No Obstacles_s.mat'\n",
    "cp2_path = '/home/diya/Documents/rat-fes/data/filipe_data/N5/N5_171001_No Obstacles_s.mat'\n",
    "'N5_171016_No Obstacles_s.mat'\n",
    "'N5_171130_No Obstacles_s.mat'\n",
    "\n",
    "n6\n",
    "'N6_171026_No Obstacles_s.mat'\n",
    "'N6_171204_No Obstacles_s.mat'\n",
    "'N6_171211_No Obstacles_s.mat'\n",
    "\n",
    "n9\n",
    "'N9_171121_No Obstacles_s.mat'  'N9_171204_No Obstacles_s.mat'  'N9_171211_No Obstacles_s.mat'  'N9_171214_No Obstacles_s.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e9213-8c74-4409-be88-b021add720e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
