{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38d943b-3061-42d1-a699-5ab81a489e6e",
   "metadata": {},
   "source": [
    "# regression decoder test (~10/6/22) (FOR FILIPE DATA ONLY)\n",
    "this compares a fixed decoder, pca decoder, cca transformation (w/ day0 decoder), and a regression decoder on day-N data. the latter two use a day-0 data as a prior start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff2fbb-e579-471f-b42c-e51c222d33fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.folder_handler import *\n",
    "from src.cort_processor import *\n",
    "from src.cca_processor import *\n",
    "from src.tdt_support import *\n",
    "from src.plotter import *\n",
    "from src.decoders import *\n",
    "from src.utils import *\n",
    "import pickle\n",
    "import scipy as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "from src.wiener_filter import *\n",
    "from matplotlib.pyplot import cm\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "import os\n",
    "from itertools import cycle, islice\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f520d7-3e89-4813-b233-90fda2b595d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# set paths/create objects\n",
    "\n",
    "cp1 = day-0\n",
    "\n",
    "cp2 = day-n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb9199-b678-441f-b55a-92e2a31c7447",
   "metadata": {
    "tags": []
   },
   "source": [
    "# patdump\n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N5_171001_proc.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp1=pickle.load(inp)\n",
    "    \n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N5_171016_proc.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp2=pickle.load(inp)\n",
    "    \n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N5_171130_proc.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp3=pickle.load(inp)\n",
    "    \n",
    "----\n",
    "\n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N6_171026_proc.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp1=pickle.load(inp)\n",
    "    \n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N6_171204_proc.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp2=pickle.load(inp)\n",
    "    \n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N6_171211_proc.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp3=pickle.load(inp)\n",
    "    \n",
    "----\n",
    "\n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N5_mixed.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp1 = pickle.load(inp)\n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N6_mixed.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp2 = pickle.load(inp)\n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N9_mixed.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp3 = pickle.load(inp)\n",
    "    \n",
    "----\n",
    "\n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N9_171121_proc.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp1=pickle.load(inp)\n",
    "    \n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N9_171204_proc.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp2=pickle.load(inp)\n",
    "    \n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N9_171211_proc.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp3=pickle.load(inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c31a27-24a5-4deb-8614-d6e00505712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/diya/Documents/rat-fes/data/pickles/N6_171026_proc.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp1=pickle.load(inp)\n",
    "    \n",
    "with open('/home/diya/Documents/rat-fes/data/pickles/N6_171204_proc.pkl', 'rb') as inp: #YOUR PATH HERE\n",
    "    cp2=pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d38c23-b53d-4187-91ad-7efbf9a6e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsampling list, percent of total data\n",
    "subsample_list = np.arange(.005, .5, .005)\n",
    "#subsample_list = [0.01, 0.02, 0.2, 0.5, 1.0]\n",
    "nummy = cp2.data['rates'][0].shape[0]\n",
    "#newlist = [int(sub * nummy) for sub in subsample_list]\n",
    "\n",
    "#print(f'num_samples:{newlist}')\n",
    "#print(subsample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19955fa1-7e62-47c4-a25e-f425605056eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dims=8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ed850-3711-4a76-b317-7c5d551645ba",
   "metadata": {},
   "source": [
    "# getting day0 decoder\n",
    "apply PCA (based on all data), and then train wiener filter.\n",
    "also get a day0-scaled-weights-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f97f4b-6819-4355-bbbc-4305ad07ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get day0 decoder weights, scaled + unscaled versions\n",
    "\n",
    "day0_decoder, nada, naday, nadax = cp1.decode_angles(X=cp1.apply_PCA(dims=pca_dims))\n",
    "day0_transformer = cp1.pca_object\n",
    "#lowest_num_dimensions = cp1.num_components\n",
    "print(np.average(nada, 1)[1])\n",
    "\n",
    "X_tempy =cp1.apply_PCA(pca_dims)\n",
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(np.squeeze(X_tempy))\n",
    "day0_decoder_scale, nada, naday, nadax = cp1.decode_angles(X=[X_scale])\n",
    "\n",
    "print(np.average(nada, 1)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac01f04-61bd-4eff-be09-f61b318681f7",
   "metadata": {},
   "source": [
    "# holding out test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53577397-a42f-447f-9e19-5db41a147d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifty_percent = int(.8 * nummy)\n",
    "cp2_test = copy.deepcopy(cp2)\n",
    "\n",
    "cp2.data['rates'] = [cp2.data['rates'][0][:fifty_percent,:]]\n",
    "cp2.data['angles'] = [cp2.data['angles'][0][:fifty_percent,:]]\n",
    "\n",
    "cp2_test.data['rates']= [cp2_test.data['rates'][0][fifty_percent:,:]]\n",
    "cp2_test.data['angles']= [cp2_test.data['angles'][0][fifty_percent:,:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0409b48-79f7-4e45-9c1f-513fa30e650a",
   "metadata": {},
   "source": [
    "# getting fixed decoder scores\n",
    "1) we subsample Day-N data, and fit PCA transformation. \n",
    "2) we transform entire Day-N data, and decode using Day0 decoder.\n",
    "\n",
    "# getting PCA decoder scores\n",
    "1) we subsample Day-N data, fit PCA transformation, and then transform it. \n",
    "2) We train new PCA decoder on only this low-D subsampled data\n",
    "3) We transform entire Day-N data, and decode using this new PCA decoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00dfee-7532-4721-b656-2d911659e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_decoder_scores = []\n",
    "pca_decoder_scores = []\n",
    "pca_predic=[]\n",
    "number_of_gaits=[]\n",
    "\n",
    "for i in range(len(subsample_list)):\n",
    "    sub_x, sub_y = cp2.subsample(percent = subsample_list[i])\n",
    "    gait_counter = sub_y\n",
    "    temp_gaits, nada = cp2.get_gait_indices(Y=sub_y)\n",
    "    number_of_gaits.append(temp_gaits[0].size - 1)\n",
    "    #apply PCA just using subsampled data\n",
    "    sub_x_pca = cp2.apply_PCA(dims=pca_dims, X=sub_x)\n",
    "    #save PCA transformation\n",
    "    pca_object = cp2.pca_object\n",
    "    #train PCA decoder \n",
    "    temp_h, nada, nadax, naday = cp2.decode_angles(X=sub_x_pca, Y=sub_y)\n",
    "    \n",
    "    test_x_fixed = np.squeeze(np.array(cp2_test.apply_PCA(dims=pca_dims, transformer = day0_transformer)))\n",
    "    test_y = np.squeeze(np.array(cp2_test.data['angles']))\n",
    "    \n",
    "    test_x_fixed_format, test_y_format = format_data(test_x_fixed, test_y)\n",
    "    \n",
    "    \n",
    "    temp_y = test_wiener_filter(test_x_fixed_format, day0_decoder)\n",
    "    fixed_decoder_scores.append(vaf(test_y_format[:,1], temp_y[:,1]))\n",
    "    \n",
    "    test_x_pca = np.squeeze(np.array(cp2_test.apply_PCA(dims=pca_dims, transformer = pca_object)))\n",
    "    \n",
    "    test_x_pca_format, nada = format_data(test_x_pca, test_y)\n",
    "    \n",
    "    temp_y = test_wiener_filter(test_x_pca_format, temp_h)\n",
    "    pca_decoder_scores.append(vaf(test_y_format[:,1], temp_y[:,1]))\n",
    "    \n",
    "    pca_predic.append(temp_y)\n",
    "\n",
    "print(fixed_decoder_scores)\n",
    "print(pca_decoder_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4288efb-3b3a-4193-aeed-091a173367b3",
   "metadata": {},
   "source": [
    "# cca decoder\n",
    "\n",
    "1) We subsample Day-N data\n",
    "2) We align Day-N subsampled data to Day-0 data\n",
    "3) We fit PCA transformation on subsampled Day-n data, and then transform it\n",
    "4) We fit a CCA transformation on subsampled, low-D day-N data\n",
    "5) We apply our PCA transformation to entire Day-N, and then apply our CCA transformation to entire low-D day-N data\n",
    "6) We decode this using Day-0 decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ec33a-9b31-49a4-b5b6-a23660474c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_decoder_scores = []\n",
    "cca_transformers=[]\n",
    "for i in range(len(subsample_list)):\n",
    "    #make subsampled cp2\n",
    "    temp_cp2 = copy.deepcopy(cp2)\n",
    "    sub_x2, sub_y2 = temp_cp2.subsample(percent = subsample_list[i])\n",
    "    \n",
    "    temp_cp2.data['rates'] = sub_x2\n",
    "    temp_cp2.data['angles'] = sub_y2\n",
    "    \n",
    "    temp_cca = CCAProcessor(cp1, temp_cp2)\n",
    "    \n",
    "    pca_sub_x1, pca_sub_x2 = temp_cca.apply_PCA(preset_num_components=pca_dims, day_0_transformer =day0_transformer)\n",
    "    temp_cca_transformer, nada = temp_cca.apply_CCA(preset_num_components = pca_dims, pca=True)\n",
    "    \n",
    "    cca_transformers.append(temp_cca_transformer)\n",
    "    \n",
    "    test_x = np.squeeze(np.array(cp2_test.apply_PCA(dims=pca_dims, transformer = temp_cca.data['cp2']['pca_transformer'])))\n",
    "    test_y = np.squeeze(np.array(cp2_test.data['angles']))\n",
    "    \n",
    "    nada, test_x_cca_space = temp_cca_transformer.transform(test_x, test_x)\n",
    "    \n",
    "    temp_x = temp_cca_transformer.inverse_transform(test_x_cca_space)\n",
    "    \n",
    "    temp_x_format, test_y_format = format_data(temp_x, test_y)\n",
    "    predic = test_wiener_filter(temp_x_format, day0_decoder)\n",
    "    \n",
    "    cca_decoder_scores.append(vaf(test_y_format[:,1], predic[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb28724-8f37-4ca3-8c07-77bf80fe72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_decoder_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af66572-df24-4048-b460-00fbb083c696",
   "metadata": {},
   "source": [
    "# regression fit\n",
    "1) We subsample day-n data, fit PCA transformation, and then transform it\n",
    "2) We then transform it using CCA transformation corresponding to same subsample we got in the CCA part. \n",
    "3) We scale it. #TODO try using day0 scale to transform it\n",
    "4) We feed this subsampled, low-d, CCA-transformed day-n data into our regression decoder. It spits out a new decoder.\n",
    "5) We take entire Day-N data, transform it with both PCA/CCA corresponding to subsample, scale it, and then decode using our new decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a8afdf-80c9-44d4-bbba-93b4664083c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_scores = []\n",
    "r_predic=[]\n",
    "pinv_scores=[]\n",
    "pinv_predic_all = []\n",
    "day0_decoder_no_offset = day0_decoder[1:,:]\n",
    "offset = day0_decoder[0,:]\n",
    "\n",
    "for i in range(len(subsample_list)):\n",
    "    #subsample day-n unprocessed data\n",
    "    sub_x, sub_y = cp2.subsample(percent = subsample_list[i])\n",
    "    \n",
    "    #apply PCA to subsampled data\n",
    "    sub_x_pca = np.squeeze(cp2.apply_PCA(dims=pca_dims, X=sub_x))\n",
    "    #transform PCA subsample to day-0 shape\n",
    "    nada, sub_x_cca_space = cca_transformers[i].transform(sub_x_pca, sub_x_pca)\n",
    "    temp_x = cca_transformers[i].inverse_transform(sub_x_cca_space)\n",
    "    #scale transformed data \n",
    "    scaler = StandardScaler()\n",
    "    temp_x_scale = scaler.fit_transform(temp_x)\n",
    "    \n",
    "    temp_x_format, temp_y_format = format_data(temp_x_scale, sub_y[0])\n",
    "    wpost, nada = ridge_fit(b0=day0_decoder_scale, x_format = temp_x_format, y_format = temp_y_format, my_alpha=100.0)\n",
    "    \n",
    "    \n",
    "    #pinv fit\n",
    "    pinv_clf = temp_cca.apply_pinv_transform(x=sub_x[0], y=sub_y[0], decoder=day0_decoder) \n",
    "    \n",
    "    \n",
    "    ###now lets test on full dataset\n",
    "    test_x = np.squeeze(np.array(cp2_test.apply_PCA(dims=pca_dims, transformer = cp2.pca_object)))\n",
    "    test_y = np.squeeze(np.array(cp2_test.data['angles']))\n",
    "    \n",
    "    raw_test_x = cp2_test.data['rates'][0]\n",
    "    raw_test_y = cp2_test.data['angles'][0]\n",
    "    \n",
    "    raw_test_x_format, raw_test_y_format = format_data(raw_test_x, raw_test_y)\n",
    "    trans_test_x = pinv_clf.predict(raw_test_x_format)\n",
    "    pinv_predict = np.dot(trans_test_x, day0_decoder_no_offset) + offset\n",
    "    \n",
    "    pinv_predic_all.append(pinv_predict)\n",
    "    \n",
    "    nada, test_xx = temp_cca.apply_CCA(cp2_x = test_x, transformer = cca_transformers[i])\n",
    "    test_xx_scale = scaler.transform(test_xx)\n",
    "    test_xx_scale_format, nada = format_data(test_xx_scale, test_y)\n",
    "    temp_y = test_wiener_filter(test_xx_scale_format, wpost)\n",
    "    \n",
    "    r_predic.append(temp_y)  \n",
    "    r_scores.append(vaf(test_y_format[:,1], temp_y[:,1]))\n",
    "    pinv_scores.append(vaf(test_y_format[:,1], pinv_predict[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f36073-6a75-49f7-bec8-98828e83a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# %matplotlib widget\n",
    "\n",
    "# plot_dict = {}\n",
    "# plot_dict['fixed_decoder_scores'] = fixed_decoder_scores\n",
    "# plot_dict['pca_decoder_scores'] = pca_decoder_scores\n",
    "# plot_dict['cca_decoder_scores'] = cca_decoder_scores\n",
    "# plot_dict['preloaded_decoder_scores'] = r_scores\n",
    "# #plot_dict['pinv_scores'] = pinv_scores\n",
    "\n",
    "# index = number_of_gaits\n",
    "\n",
    "# df = pd.DataFrame(data=plot_dict, index=index)\n",
    "\n",
    "# my_colors = list(islice(cycle(['tab:red', 'tab:blue', 'tab:green', 'tab:orange', 'yellow', 'k']), None, len(df)))\n",
    "\n",
    "  \n",
    "# # plot grouped bar chart\n",
    "# ax = df.plot.bar(rot=15, color=my_colors)\n",
    "# ax.set_ylim(bottom=-1, top=1)\n",
    "# ax.set_title('Training various decoders, testing on last 20% of day-n data')\n",
    "# ax.set_ylabel('vaf')\n",
    "# ax.set_xlabel('number of gait cycles trained on (from first 20% of data)')\n",
    "# ax.legend(loc='lower right')\n",
    "# for container in ax.containers:\n",
    "#     diya = ax.bar_label(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e57165-3d3a-4c11-9ae2-5a61e65ea668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig0 = plt.figure()\n",
    "# ax0 = fig0.add_subplot(311)\n",
    "# ts = np.arange(0, test_y_format.shape[0]/50, 1/50)\n",
    "\n",
    "# num = 4 \n",
    "\n",
    "# legend1=['actual', 'pca_predic']\n",
    "# legend2 = ['actual', 'preload_predic']\n",
    "# legend3=['actual','pinv_predic']\n",
    "\n",
    "\n",
    "# ax0.plot(ts, test_y_format[:,1])\n",
    "# ax0.plot(ts, pca_predic[num][:,1])\n",
    "# ax0.legend(legend1, loc='lower right')\n",
    "\n",
    "# ax01 = fig0.add_subplot(312, sharex=ax0)\n",
    "# ax01.plot(ts, test_y_format[:,1])\n",
    "# ax01.plot(ts, r_predic[num][:,1])\n",
    "# ax01.legend(legend2, loc='lower right')\n",
    "\n",
    "# ax02 = fig0.add_subplot(313, sharex=ax0)\n",
    "# ax02.plot(ts, test_y_format[:,1])\n",
    "# ax02.plot(ts, pinv_predic_all[num][:,1])\n",
    "# ax02.legend(legend3, loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adc6f60-38d8-4acd-bc42-f992471d9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "ax1= fig1.add_subplot(111)\n",
    "x = subsample_list\n",
    "ax1.set_ylim(bottom=-1, top=1)\n",
    "#ax1.scatter(number_of_gaits, fixed_decoder_scores, color='tab:olive')\n",
    "ax1.plot(number_of_gaits, fixed_decoder_scores, '--', color='tab:red')\n",
    "ax1.scatter(number_of_gaits, pca_decoder_scores, color='tab:blue')\n",
    "ax1.plot(number_of_gaits, pca_decoder_scores, color='tab:blue')\n",
    "ax1.scatter(number_of_gaits, cca_decoder_scores, color='tab:green')\n",
    "ax1.plot(number_of_gaits, cca_decoder_scores, color='tab:green')\n",
    "ax1.scatter(number_of_gaits, r_scores, color='tab:orange')\n",
    "ax1.plot(number_of_gaits, r_scores, color='tab:orange')\n",
    "#ax1.scatter(number_of_gaits, pinv_scores, color='tab:olive')\n",
    "#ax1.plot(number_of_gaits, pinv_scores, color='tab:olive')\n",
    "\n",
    "\n",
    "legend11 = ['fixed decoder', 'pca decoder', 'cca aligned', 'preloaded decoder']\n",
    "\n",
    "ax1.set_xlim(0,100)\n",
    "ax1.set_xlabel('number of gait cycles')\n",
    "ax1.set_ylabel('vaf')\n",
    "ax1.legend(legend11, loc='lower right')\n",
    "print(number_of_gaits[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980b47a3-7603-4c33-98b6-b7137b0e4328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97f62db9-dc86-49f0-a902-54a4779c1f0f",
   "metadata": {},
   "source": [
    "# notes\n",
    "\n",
    "cp1_path = '/home/diya/Documents/rat-fes/data/filipe_data/N5/N5_171016_No Obstacles_s.mat'\n",
    "cp2_path = '/home/diya/Documents/rat-fes/data/filipe_data/N6/N6_171204_No Obstacles_s.mat'\n",
    "\n",
    "with these two, regression is good vaf score but in practicality something seems off!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e1ae2-4e5e-4360-a6f8-bbc9ac656fa2",
   "metadata": {},
   "source": [
    "# paths\n",
    "\n",
    "N5 \n",
    "cp1_path = '/home/diya/Documents/rat-fes/data/filipe_data/N5/N5_170929_No Obstacles_s.mat'\n",
    "cp2_path = '/home/diya/Documents/rat-fes/data/filipe_data/N5/N5_171001_No Obstacles_s.mat'\n",
    "'N5_171016_No Obstacles_s.mat'\n",
    "'N5_171130_No Obstacles_s.mat'\n",
    "\n",
    "n6\n",
    "'N6_171026_No Obstacles_s.mat'\n",
    "'N6_171204_No Obstacles_s.mat'\n",
    "'N6_171211_No Obstacles_s.mat'\n",
    "\n",
    "n9\n",
    "'N9_171121_No Obstacles_s.mat'  'N9_171204_No Obstacles_s.mat'  'N9_171211_No Obstacles_s.mat'  'N9_171214_No Obstacles_s.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e9213-8c74-4409-be88-b021add720e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
